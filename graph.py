"""
Lab 3: graph.py
Adaptive Learning Companion â€” LangGraph ReAct Agent
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Implements a ReAct (Reason + Act) loop using LangGraph:
  1. Agent Node  â€” LLM reasons and decides which tool (if any) to call
  2. Tool Node   â€” Executes the chosen tool and returns the result
  3. Router      â€” If tool calls exist â†’ loop to Tool Node; else â†’ END

State flows:  START â†’ agent â†’ [tools â†’ agent]* â†’ END

Install:
    pip install langgraph langchain langchain-openai langchain-core openai python-dotenv
"""

import os
from typing import Annotated
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from typing_extensions import TypedDict

from tools import retrieve_content, get_student_progress, update_student_progress

load_dotenv()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GRAPH STATE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class AgentState(TypedDict):
    """
    Shared state passed between every node in the graph.

    `messages` uses the `add_messages` reducer so each node
    appends to the history rather than overwriting it.
    This gives the LLM full conversation + tool-call context.
    """
    messages: Annotated[list, add_messages]


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LLM SETUP
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

TOOLS = [retrieve_content, get_student_progress, update_student_progress]

llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0.3,
    api_key=os.getenv("OPENAI_API_KEY")
).bind_tools(TOOLS)

SYSTEM_PROMPT = """You are an Adaptive Learning Companion â€” a patient, encouraging AI tutor.

Your job is to help students master concepts step-by-step using this workflow:

1. ASSESS   â€“ Find out what the student already knows (ask a diagnostic question).
2. CHECK    â€“ Call get_student_progress to see their mastery score for this topic.
3. PREREQS  â€“ If mastery < 0.7, call retrieve_content(..., "prerequisites", ...) first.
4. EXPLAIN  â€“ Call retrieve_content(..., "explanation", ...) to ground your explanation.
5. PRACTICE â€“ Call retrieve_content(..., "practice", ...) to give them a problem.
6. EVALUATE â€“ Ask the student to answer, then judge their response (score 0.0â€“1.0).
7. UPDATE   â€“ Call update_student_progress with the score.
8. DECIDE   â€“ If mastery â‰¥ 0.7, move to next concept. Else repeat with harder focus.

Rules:
- Always ground explanations in retrieved content â€” never rely solely on your memory.
- Use analogies and examples appropriate to the student's difficulty level.
- Be encouraging. Normalise mistakes as part of learning.
- Only call update_student_progress AFTER the student has answered a question.
"""


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# NODE 1: AGENT
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def agent_node(state: AgentState) -> AgentState:
    """
    The brain of the agent.
    Takes the current message history, calls the LLM (with tools bound),
    and returns the LLM's response (which may contain tool call requests).
    """
    messages = [SystemMessage(content=SYSTEM_PROMPT)] + state["messages"]
    response = llm.invoke(messages)
    return {"messages": [response]}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# NODE 2: TOOL NODE
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# LangGraph's built-in ToolNode automatically:
#   - Reads tool_calls from the last AIMessage
#   - Executes the matching tool function
#   - Appends ToolMessage results back to state
tool_node = ToolNode(tools=TOOLS)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CONDITIONAL ROUTER (the "logic gate")
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def router(state: AgentState) -> str:
    """
    Inspect the last message from the agent.
    - If it contains tool_calls â†’ route to 'tools' node (keep looping)
    - If no tool_calls         â†’ route to END (final answer ready)
    """
    last_message = state["messages"][-1]

    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tools"

    return END


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# BUILD THE GRAPH
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_graph() -> StateGraph:
    """
    Assemble and compile the LangGraph StateGraph.

    Graph structure:
        START
          â”‚
          â–¼
        agent â”€â”€(has tool calls?)â”€â”€â–º tools
          â–²                            â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
        (no tool calls)
          â”‚
          â–¼
         END
    """
    graph = StateGraph(AgentState)

    # Register nodes
    graph.add_node("agent", agent_node)
    graph.add_node("tools", tool_node)

    # Entry point
    graph.set_entry_point("agent")

    # Conditional edge from agent: call router to decide next step
    graph.add_conditional_edges(
        source="agent",
        path=router,
        path_map={
            "tools": "tools",
            END: END
        }
    )

    # After tools run â†’ always return to agent for next reasoning step
    graph.add_edge("tools", "agent")

    return graph.compile()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# RUN (interactive CLI loop)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_agent():
    """Interactive CLI to chat with the learning agent."""
    app = build_graph()

    print("\n" + "="*60)
    print("  ADAPTIVE LEARNING COMPANION")
    print("  Powered by LangGraph ReAct Agent")
    print("="*60)
    print("  Type 'quit' to exit.\n")

    student_id = input("Enter your student ID (or press Enter for 'student_001'): ").strip()
    if not student_id:
        student_id = "student_001"

    conversation_history = []

    while True:
        user_input = input(f"\nYou: ").strip()
        if user_input.lower() in ("quit", "exit", "q"):
            print("\nGoodbye! Keep studying! ðŸ“š")
            break
        if not user_input:
            continue

        # Inject student context into message
        contextual_input = f"[Student ID: {student_id}] {user_input}"
        conversation_history.append(HumanMessage(content=contextual_input))

        # Run one full ReAct cycle
        result = app.invoke({"messages": conversation_history})

        # Extract final assistant message
        final_message = result["messages"][-1]
        print(f"\nAgent: {final_message.content}")

        # Update history for multi-turn memory
        conversation_history = result["messages"]


if __name__ == "__main__":
    run_agent()